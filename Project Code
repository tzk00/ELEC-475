# Import linear_kernel
from sklearn.metrics.pairwise import linear_kernel
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

# Importing dataset
file_path = 'NetflixRatings.csv'
try:
    df1 = pd.read_csv(file_path, encoding='utf-8')
except UnicodeDecodeError:
    try:
        df1 = pd.read_csv(file_path, encoding='latin1')
    except UnicodeDecodeError:
        df1 = pd.read_csv(file_path, encoding='ISO-8859-1')
print(df1.head())


# Removing duplicates and view data
unique_shows = df1[['Show ID', 'Title']].drop_duplicates()

if unique_shows['Show ID'].nunique() != unique_shows.shape[0]:
    print("Error")
else:

    average_ratings = df1.groupby('Show ID')['Customer Rating'].mean().reset_index(name='vote_average')
    count_ratings = df1.groupby('Show ID')['Customer Rating'].count().reset_index(name='vote_count')

    result = pd.merge(unique_shows, average_ratings, on='Show ID')
    result = pd.merge(result, count_ratings, on='Show ID')

    print(result.head())

    #output_path = '/content/drive/My Drive/475/Project/average_votes_corrected.csv'
    #result.to_csv(output_path, index=False)
    #print(f"Output pathï¼š{output_path}")

####### Demographic Filtering ########
# Mean votes
df2=pd.read_csv('average_votes_corrected.csv')
C= df2['vote_average'].mean()
C
# We have to determine the minimum votes required to be listed in the chart. We will use 90th percentile as our cutoff. 
q_movies = df2.copy().loc[df2['vote_count'] >= m]
q_movies.shape

# Weighted Rating Formula
def weighted_rating(x, m=m, C=C):
    v = x['vote_count']
    R = x['vote_average']
    # Calculation based on the IMDB formula
    return (v/(v+m) * R) + (m/(m+v) * C)

# Define a new feature 'score' and calculate its value with `weighted_rating()`
q_movies['score'] = q_movies.apply(weighted_rating, axis=1)

# Sort movies based on score calculated above
q_movies = q_movies.sort_values('score', ascending=False)

# Print the top 15 movies
q_movies[['Title', 'vote_count', 'vote_average', 'score']].head(10)

# Plot the most popular movie based on vote_count
pop= df2.sort_values('vote_count', ascending=False)
import matplotlib.pyplot as plt
plt.figure(figsize=(12,4))

plt.barh(pop['Title'].head(6),pop['vote_count'].head(6), align='center',
        color='skyblue')
plt.gca().invert_yaxis()
plt.xlabel("Popularity")
plt.title("Popular Movies")

######## Feature-based Model (Training model using movie description only) ########

# Import data
df3=pd.read_csv ('small_matched_movies.csv')
df3['description'].head(5)

# Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'
tfidf = TfidfVectorizer(stop_words='english')

# Replace NaN with an empty string
df3['description'] = df3['description'].fillna('')

# Construct the required TF-IDF matrix by fitting and transforming the data
tfidf_matrix = tfidf.fit_transform(df3['description'])

# Output the shape of tfidf_matrix
tfidf_matrix.shape

# Compute the cosine similarity matrix
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)

# Construct a reverse map of indices and movie titles
indices = pd.Series(df3.index, index=df3['title']).drop_duplicates()

# Function that takes in movie title as input and outputs most similar movies
def get_recommendations(title, cosine_sim=cosine_sim):
    # Get the index of the movie that matches the title
    idx = indices[title]

    # Get the pairwsie similarity scores of all movies with that movie
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Sort the movies based on the similarity scores
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Get the scores of the 10 most similar movies
    sim_scores = sim_scores[1:11]

    # Get the movie indices
    movie_indices = [i[0] for i in sim_scores]

    # Return the top 10 most similar movies
    return df3['title'].iloc[movie_indices]

# Get recommendation
get_recommendations('stuart little 2')

######## Feature-based Model (Training model using movie description , cast, genre and director ) ########

# Modifying format of data in listed_in column to [{"id": x, "genre": "genre1"}, {"id":y, "genre": "genre2"}]
unique_genres = set()
for genres in df3['listed_in'].str.split(', '):
    unique_genres.update(genres)

genre_id_mapping = {genre: idx for idx, genre in enumerate(unique_genres, start=1)}

def modify_listed_in(genres):
    return [{"id": genre_id_mapping[genre], "name": genre} for genre in genres]

df3['listed_in'] = df3['listed_in'].str.split(', ').apply(modify_listed_in)

## Modifying format for cast column so that it is same as the format in listed_in column
df3['cast'] = df3['cast'].fillna('')

unique_cast = set()
for cast_list in df3['cast'].str.split(', '):
    unique_cast.update(cast_list)

cast_id_mapping = {cast_member: idx for idx, cast_member in enumerate(unique_cast, start=1)}

def modify_cast(cast_list):
    return [{"id": cast_id_mapping[cast_member], "name": cast_member} for cast_member in cast_list]

df3['cast'] = df3['cast'].str.split(', ').apply(modify_cast)

## Modifying format for description column so that it is same as the format in listed_in column
df3['description'] = df3['description'].fillna('')
unique_words = set()
for description in df3['description']:
    words = [word.strip('.,') for word in description.split()]
    unique_words.update(words)

word_id_mapping = {word: idx for idx, word in enumerate(unique_words, start=1)}

def modify_description(description):
    words = [word.strip('.,') for word in description.split()]
    return [{"id": word_id_mapping[word], "name": word} for word in words]

df3['description'] = df3['description'].apply(modify_description)

df3.head(5)

# Returns the list top 3 elements or entire list; whichever is more.
def get_list(x):
    if isinstance(x, list):
        names = [i['name'] for i in x]
        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.
        if len(names) > 3:
            names = names[:3]
        return names

    #Return empty list in case of missing/malformed data
    return []

# Define new director, cast, genres and keywords features that are in a suitable form.
df3['director'] = df3['director']

features = ['listed_in', 'cast', "description"]
for feature in features:
    df3[feature] = df3[feature].apply(get_list)

# Print the new features of the first 3 films
df3[['title', 'cast', 'director','listed_in', "description"]].head(3)

# Function to convert all strings to lower case and strip names of spaces
def clean_data(x):
    if isinstance(x, list):
        return [str.lower(i.replace(" ", "")) for i in x]
    else:
        #Check if director exists. If not, return empty string
        if isinstance(x, str):
            return str.lower(x.replace(" ", ""))
        else:
            return ''
        
# Apply clean_data function to your features.
features = ['cast', 'description', 'director', 'listed_in']

for feature in features:
    df3[feature] = df3[feature].apply(clean_data)

# Create metadata string
def create_soup(x):
    return ' '.join(x['description']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['listed_in'])
df3['soup'] = df3.apply(create_soup, axis=1)

# Create the count matrix

count = CountVectorizer(stop_words='english')
count_matrix = count.fit_transform(df3['soup'])

# Compute the Cosine Similarity matrix based on the count_matrix
cosine_sim2 = cosine_similarity(count_matrix, count_matrix)

# Reset index of our main DataFrame and construct reverse mapping as before
df3 = df3.reset_index()
indices = pd.Series(df3.index, index=df3['title'])

get_recommendations('stuart little 2', cosine_sim2)